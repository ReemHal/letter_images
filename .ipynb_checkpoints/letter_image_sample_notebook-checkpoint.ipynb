{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Notebook: Exploring a Tabled Image Dataset\n",
    "\n",
    "The script *extract_info_from_dataset.py* extracts information from a dataset of letter images and saves the extracted information in a csv file. This notebook demonstrates how the information can be used to explore the dataset and retrieve letter images satistfying given criteria such as the date it was written, the recipient of the letter, or its signator. Along with the *letter_image* class, the information can also be used to find letters similar to a letter image not in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import letter_image as li\n",
    "import os\n",
    "import nltk.tag.stanford as st\n",
    "from ast import literal_eval\n",
    "\n",
    "dataset_dir = \"/media/datadr/datasets/letters\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data Table from the CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data table fromt he csv file\n",
    "data_file_name= \"infoTable.csv\"\n",
    "data = pd.read_csv(data_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data table: a closer look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the table represents a semantic segment or part of the image whose name is **image_name**.\n",
    "The table consists of:\n",
    "    -  an **image_name** column \n",
    "    -  a **dir** column giving the path to teh image\n",
    "    -  a **part** column which contains the name of the current part. Currently this is one of: \n",
    "        -  heading/sender \n",
    "        -  recipient\n",
    "        -  greeting\n",
    "        -  body\n",
    "        -  signature\n",
    "        -  date\n",
    "        -  enclosures/notes\n",
    "    -  a **contour** column which is a list of contours each representing a block of the current part. \n",
    "    -  a **text** column which is a list representing the OCR recognized text within the contours in **contour**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>dir</th>\n",
       "      <th>contour</th>\n",
       "      <th>text</th>\n",
       "      <th>part</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>letter_1135</td>\n",
       "      <td>/media/datadr/datasets/letters</td>\n",
       "      <td>[array([[ 395.        , 1417.66887443],\\n     ...</td>\n",
       "      <td>['HILL\\n\\nW\\n\\nlﬂcﬂlPCIATID 1.7!\\n\\nO\\nQ\\nC\\nO...</td>\n",
       "      <td>heading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>letter_1135</td>\n",
       "      <td>/media/datadr/datasets/letters</td>\n",
       "      <td>[array([[928.        , 578.84663755],\\n       ...</td>\n",
       "      <td>['2013']</td>\n",
       "      <td>date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>letter_1135</td>\n",
       "      <td>/media/datadr/datasets/letters</td>\n",
       "      <td>[array([[938.        , 438.44451491],\\n       ...</td>\n",
       "      <td>['April', 'M.Sc.', 'Elliott Bay', 'Mr.', 'Kids...</td>\n",
       "      <td>recipient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>letter_1135</td>\n",
       "      <td>/media/datadr/datasets/letters</td>\n",
       "      <td>[array([[1389.        ,  483.4266401 ],\\n     ...</td>\n",
       "      <td>['Dear']</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>letter_1135</td>\n",
       "      <td>/media/datadr/datasets/letters</td>\n",
       "      <td>[array([[1500.        , 1560.20216494],\\n     ...</td>\n",
       "      <td>['Hill', 'Chamber', 'Richmond', 'you on receiv...</td>\n",
       "      <td>body</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_name                             dir  \\\n",
       "0  letter_1135  /media/datadr/datasets/letters   \n",
       "1  letter_1135  /media/datadr/datasets/letters   \n",
       "2  letter_1135  /media/datadr/datasets/letters   \n",
       "3  letter_1135  /media/datadr/datasets/letters   \n",
       "4  letter_1135  /media/datadr/datasets/letters   \n",
       "\n",
       "                                             contour  \\\n",
       "0  [array([[ 395.        , 1417.66887443],\\n     ...   \n",
       "1  [array([[928.        , 578.84663755],\\n       ...   \n",
       "2  [array([[938.        , 438.44451491],\\n       ...   \n",
       "3  [array([[1389.        ,  483.4266401 ],\\n     ...   \n",
       "4  [array([[1500.        , 1560.20216494],\\n     ...   \n",
       "\n",
       "                                                text       part  \n",
       "0  ['HILL\\n\\nW\\n\\nlﬂcﬂlPCIATID 1.7!\\n\\nO\\nQ\\nC\\nO...    heading  \n",
       "1                                           ['2013']       date  \n",
       "2  ['April', 'M.Sc.', 'Elliott Bay', 'Mr.', 'Kids...  recipient  \n",
       "3                                           ['Dear']   greeting  \n",
       "4  ['Hill', 'Chamber', 'Richmond', 'you on receiv...       body  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What letter parts are in the table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['heading', 'date', 'recipient', 'greeting', 'body', 'signature',\n",
       "       'enclosures', nan], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Letter parts\n",
    "data.part.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show a sample of the letters' dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                  ['2013']\n",
       "6      ['November 8. 2007']\n",
       "10                  ['may']\n",
       "13    ['September 1, 2018']\n",
       "26       ['March 10, 2016']\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dates in database\n",
    "data[data.part=='date'].text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do we have letters in the database signed by a given signator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we have letters in the database signed by a given signator?\n",
    "given_signator = \"Joan Lau\"\n",
    "\n",
    "stanfordNER_path = \"/home/reem/tools/stanford-ner-2018-10-16/\"\n",
    "english_nertagger = st.StanfordNERTagger(os.path.join(stanfordNER_path,\\\n",
    "                              \"classifiers/english.all.3class.distsim.crf.ser.gz\"), \\\n",
    "                              os.path.join(stanfordNER_path,\\\n",
    "                                           \"stanford-ner.jar\"))\n",
    "\n",
    "letters = []\n",
    "letters_w_sig = data[data.part=='signature']\n",
    "for i, row in letters_w_sig.iterrows():\n",
    "    for i,line in enumerate(literal_eval(row.text)):\n",
    "        for inline in line.split(\"\\n\"):\n",
    "            tagged=  english_nertagger.tag(inline.split())\n",
    "            if ('PERSON' in [tagged[i][1] for i,tup in enumerate(tagged)]):\n",
    "                if given_signator.lower() == inline.lower():\n",
    "                    letters.append(i)\n",
    "                \n",
    "if (len(letters)> 0):\n",
    "    print(\"Letters signed by {}:\".format(given_signator))\n",
    "    for i in letters:\n",
    "        print(data.iloc[i].image_name)\n",
    "else:\n",
    "    print(\"No letters in the database were signed by{}:\".format(given_signator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving letters that are similar to a new letter image\n",
    "\n",
    "Sometimes we may wish to find dataset letters that are similar to a letter not in our dataset. In this case we start by extracting information from the new letter using the *letter_image* class. We can then compare the contents of the new letter to those in the dataset to, for example, find all letters signed by the same signator, or all dataset letters written on the same day as the new letter.\n",
    "\n",
    "(Note: For more examples on how to use the letter_image class please refer to the __[letter_image_examples.ipynb](https://github.com/ReemHal/letter_images/blob/master/letter_image_examples.ipynb)__ notebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try to match our dataset letters to an new letter image\n",
    "image_name = \"test_letter\"\n",
    "letter_obj = li.letter_image(\"\", image_name)\n",
    "letter_obj.process_letter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Letter Parts\n",
    "\n",
    "First let us have a look at the parts identified within test_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_obj.display_contours(display=True,save=False,savedir='contours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text within each part\n",
    "\n",
    "Now let us have a look at the contents of each of those parts.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do we know about the test letter's content?\n",
    "test_letter_content={}\n",
    "for i,clip_item in enumerate(letter_obj.clip):\n",
    "    test_letter_content[clip_item['part']] = clip_item['text']\n",
    "    \n",
    "for key in test_letter_content.keys():\n",
    "    text = str.join(\"\\n\",[text for i,text in enumerate(test_letter_content[key])])\n",
    "    print(\"<<{}>>\\n{}\\n=====\".format(key, text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Who signed our *test_letter*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Who signed the test letter?\n",
    "\n",
    "stanfordNER_path = \"/home/reem/tools/stanford-ner-2018-10-16/\"\n",
    "english_nertagger = st.StanfordNERTagger(os.path.join(stanfordNER_path,\\\n",
    "                              \"classifiers/english.all.3class.distsim.crf.ser.gz\"), \\\n",
    "                              os.path.join(stanfordNER_path,\\\n",
    "                                           \"stanford-ner.jar\"))\n",
    "\n",
    "sig_segment = test_letter_content['signature']\n",
    "for i,line in enumerate(sig_segment):\n",
    "    tagged=  english_nertagger.tag(line.split())\n",
    "    if ('PERSON' in [tagged[i][1] for i,tup in enumerate(tagged)]):\n",
    "        signator = line\n",
    "\n",
    "print(\"Letter signed by \", signator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Who is the recipient of the letter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who was the test letter sent to?\n",
    "sig_segment = test_letter_content['recipient']\n",
    "for i,line in enumerate(sig_segment):\n",
    "    for inline in line.split(\"\\n\"):\n",
    "        tagged=  english_nertagger.tag(inline.split())\n",
    "        if ('PERSON' in [tagged[i][1] for i,tup in enumerate(tagged)]):\n",
    "            recipient_name = inline\n",
    "\n",
    "print(\"Letter was sent to \", recipient_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting things together: find similar letters in our dataset\n",
    "\n",
    "#### Retrieve letters written on the same date\n",
    "\n",
    "Now we would like to find all dataset letters that were written on the same data as the *test_letter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which letters were sent on the same day as the test letter?\n",
    "options= data[data.part=='date']\n",
    "for i, row in options.iterrows():\n",
    "    if (test_letter_content['date'][0] in  row['text']):\n",
    "        print(row['image_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Were any letters in our database  sent to the same recipient as the test letter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we have letters in the database that were sent to the same recipient?\n",
    "letters = []\n",
    "letters_w_sig = data[data.part=='recipient']\n",
    "for i, row in letters_w_sig.iterrows():\n",
    "    for i,line in enumerate(literal_eval(row.text)):\n",
    "        for inline in line.split(\"\\n\"):\n",
    "            tagged=  english_nertagger.tag(inline.split())\n",
    "            if ('PERSON' in [tagged[i][1] for i,tup in enumerate(tagged)]):\n",
    "                if recipient_name == inline.lower():\n",
    "                    letters.append(i)\n",
    "                \n",
    "if (len(letters)> 0):\n",
    "    print(\"Letters sent to{}:\".format(recipient_name))\n",
    "    for i in letters:\n",
    "        print(data.iloc[i].image_name)\n",
    "else:\n",
    "    print(\"No letters in the database were sent to {}\".format(recipient_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv",
   "language": "python",
   "name": "dl4cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
